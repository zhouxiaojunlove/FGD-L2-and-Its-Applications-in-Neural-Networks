{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import time\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "from torch import Tensor\n",
    "from scipy.special import gamma \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath, amssymb}'\n",
    "custom_params = {\n",
    "    # Font and text settings\n",
    "    'font.size': 8,                \n",
    "    'axes.labelsize': 8,           \n",
    "    'axes.titlesize': 8,           \n",
    "    'xtick.labelsize': 8,          \n",
    "    'ytick.labelsize': 8,          \n",
    "    'legend.fontsize': 6,          \n",
    "    \n",
    "    # Line properties\n",
    "    'lines.linewidth': 1.2,        \n",
    "    'lines.markersize': 4,         \n",
    "    \n",
    "    # Figure dimensions and quality\n",
    "    'figure.figsize': (3.5, 2.5),  \n",
    "    \n",
    "    # Axis properties\n",
    "    'axes.linewidth': 0.8,         \n",
    "    'grid.linewidth': 0.5,         \n",
    "    'grid.alpha': 0.3,             \n",
    "}\n",
    "\n",
    "# Apply the customized parameters to matplotlib\n",
    "plt.rcParams.update(custom_params)\n",
    "\n",
    "\n",
    "def split(X,y):\n",
    "    X_train,X_temp,y_train,y_temp = train_test_split(X,y,test_size=0.3,shuffle=False)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.666,shuffle=False)\n",
    "    return X_train,X_val,X_test,y_train,y_val,y_test\n",
    "\n",
    "def MSE(pred,true):\n",
    "    return np.mean((pred-true)**2)\n",
    "\n",
    "def MAE(pred, true):\n",
    "    return np.mean(np.abs(pred-true))\n",
    "\n",
    "def RMSE(pred,true):\n",
    "    return np.sqrt(np.mean((pred-true)**2))\n",
    "\n",
    "def MAPE(pred, true):\n",
    "    return np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def clip_matrix_norm(matrix, max_norm):\n",
    "    norm = torch.norm(matrix)\n",
    "    if norm > max_norm:\n",
    "        matrix = matrix * (max_norm / norm)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "class Fractional_Order_Matrix_Differential_Solver(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx,input1,w,b,alpha,c):\n",
    "        alpha = torch.tensor(alpha)\n",
    "        c = torch.tensor(c)\n",
    "        ctx.save_for_backward(input1,w,b,alpha,c)\n",
    "        outputs = input1@w + b\n",
    "        return outputs\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        input1,w,b,alpha,c = ctx.saved_tensors\n",
    "        x_fractional, w_fractional = Fractional_Order_Matrix_Differential_Solver.Fractional_Order_Matrix_Differential_Linear(input1,w,b,alpha,c)   \n",
    "        x_grad = grad_outputs@x_fractional\n",
    "        w_grad = w_fractional@grad_outputs\n",
    "        b_grad = grad_outputs.sum(dim=0)\n",
    "        return x_grad, w_grad, b_grad,None,None\n",
    "          \n",
    "    @staticmethod\n",
    "    def Fractional_Order_Matrix_Differential_Linear(xs,ws,b,alpha,c):\n",
    "        wf = ws[:,0].view(1,-1)\n",
    "        #main\n",
    "        w_main = torch.mul(xs,(torch.abs(wf)+1e-8)**(1-alpha)/gamma(2-alpha))\n",
    "        #partial\n",
    "        w_partial = torch.mul((xs@wf.T).expand(xs.shape) - torch.mul(xs,wf) + b[0], torch.sgn(wf)*(torch.abs(wf)+1e-8)**(-alpha)/gamma(1-alpha))\n",
    "        return ws.T, (w_main + clip_matrix_norm(w_partial,c)).transpose(-2,-1)\n",
    "\n",
    "class FLinear(nn.Module):\n",
    "    \n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, alpha=0.9, c=1.0, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.c = c\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return Fractional_Order_Matrix_Differential_Solver.apply(x, self.weight.T, self.bias, self.alpha,self.c)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"in_features={self.in_features}, out_features={self.out_features}, bias={self.bias is not None}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "class Lookahead:\n",
    "    def __init__(self, optimizer, alpha=0.5, k=6):\n",
    "        if not 0.0 < alpha <= 1.0:\n",
    "            raise ValueError(f\"Invalid alpha: {alpha}\")\n",
    "        if k < 1:\n",
    "            raise ValueError(f\"Invalid k: {k}\")\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        self.step_counter = 0\n",
    "\n",
    "        self.slow_weights = [\n",
    "            p.detach().clone()\n",
    "            for group in optimizer.param_groups\n",
    "            for p in group['params']\n",
    "        ]\n",
    "        for w in self.slow_weights:\n",
    "            w.requires_grad = False\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = self.optimizer.step(closure)\n",
    "        self.step_counter += 1\n",
    "\n",
    "        if self.step_counter % self.k == 0:\n",
    "            idx = 0\n",
    "            for group in self.optimizer.param_groups:\n",
    "                for p in group['params']:\n",
    "                    slow = self.slow_weights[idx]\n",
    "                    slow.data.add_(p.data - slow.data, alpha=self.alpha)\n",
    "                    p.data.copy_(slow.data)\n",
    "                    idx += 1\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split results:\n",
      "  Training set: 12194 samples (70.0%)\n",
      "  Validation set: 1742 samples (10.0%)\n",
      "  Test set: 3484 samples (20.0%)\n",
      "\n",
      "Sequence creation results:\n",
      "  Training set: X(11619, 192, 7), y(11619, 384)\n",
      "  Validation set: X(1167, 192, 7), y(1167, 384)\n",
      "  Test set: X(2909, 192, 7), y(2909, 384)\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "Tensor shapes:\n",
      "  X_train_tensor: torch.Size([11619, 192, 7])\n",
      "  y_train_tensor: torch.Size([11619, 384])\n",
      "  X_val_tensor: torch.Size([1167, 192, 7])\n",
      "  y_val_tensor: torch.Size([1167, 384])\n",
      "  X_test_tensor: torch.Size([2909, 192, 7])\n",
      "  y_test_tensor: torch.Size([2909, 384])\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "slide_windows_size = 192  # Input sequence length\n",
    "pred_length = 384        # Prediction horizon length\n",
    "stock = 'ETTh1'            # Dataset name (DJI for comparison)\n",
    "features_j = 6           # Target feature index (DJI:4, ETTm2:6)\n",
    "num_feature = features_j + 1         #(DJI:5, ETTm2:7)\n",
    "\n",
    "# Load data\n",
    "root = r'C:\\Users\\Administrator\\torch_zxj\\博士第四篇代码'\n",
    "df_DJIA = pd.read_csv(root+'/data/'+stock+'.csv')\n",
    "# df_DJIA = pd.read_csv(r'./data/'+stock+'.csv')\n",
    "del df_DJIA['date']  # Remove date column\n",
    "\n",
    "# 1. Split data first (7:1:2 ratio)\n",
    "def split_time_series(data, train_ratio=0.7, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Split time series data in chronological order\n",
    "    \n",
    "    Args:\n",
    "        data: Complete time series data\n",
    "        train_ratio: Proportion for training set\n",
    "        val_ratio: Proportion for validation set\n",
    "    \n",
    "    Returns:\n",
    "        train_data, val_data, test_data: Split datasets\n",
    "    \"\"\"\n",
    "    n_samples = len(data)\n",
    "    train_end = int(n_samples * train_ratio)\n",
    "    val_end = train_end + int(n_samples * val_ratio)\n",
    "    \n",
    "    # Split in chronological order (important for time series)\n",
    "    train_data = data[:train_end]\n",
    "    val_data = data[train_end:val_end]\n",
    "    test_data = data[val_end:]\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Split raw data first\n",
    "train_raw, val_raw, test_raw = split_time_series(df_DJIA.values, 0.7, 0.1)\n",
    "\n",
    "print(f\"Data split results:\")\n",
    "print(f\"  Training set: {len(train_raw)} samples ({len(train_raw)/len(df_DJIA)*100:.1f}%)\")\n",
    "print(f\"  Validation set: {len(val_raw)} samples ({len(val_raw)/len(df_DJIA)*100:.1f}%)\")\n",
    "print(f\"  Test set: {len(test_raw)} samples ({len(test_raw)/len(df_DJIA)*100:.1f}%)\")\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_raw)\n",
    "\n",
    "# Transform all datasets using training set statistics\n",
    "train_scaled = scaler.transform(train_raw)\n",
    "val_scaled = scaler.transform(val_raw)  # Use training set statistics\n",
    "test_scaled = scaler.transform(test_raw)  # Use training set statistics\n",
    "\n",
    "# 3. Create sequences for time series forecasting\n",
    "def create_sequences(data, slide_windows_size, pred_length, target_idx):\n",
    "    \"\"\"\n",
    "    Create input-output sequences for time series forecasting\n",
    "    \n",
    "    Args:\n",
    "        data: Multivariate time series data\n",
    "        slide_windows_size: Input sequence length (look-back window)\n",
    "        pred_length: Output sequence length (forecast horizon)\n",
    "        target_idx: Index of target feature to predict\n",
    "    \n",
    "    Returns:\n",
    "        X: Input sequences [samples, seq_len, features]\n",
    "        y: Target sequences [samples, pred_length]\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - slide_windows_size - pred_length + 1):\n",
    "        # Input sequence: sliding window of features\n",
    "        X.append(data[i:i+slide_windows_size, :])  # [seq_len, features]\n",
    "        # Target sequence: future values of target feature\n",
    "        y.append(data[i+slide_windows_size:i+slide_windows_size+pred_length, target_idx])  \n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "\n",
    "# Create sequences for each dataset\n",
    "X_train, y_train = create_sequences(train_scaled, slide_windows_size, pred_length, features_j)\n",
    "X_val, y_val = create_sequences(val_scaled, slide_windows_size, pred_length, features_j)\n",
    "X_test, y_test = create_sequences(test_scaled, slide_windows_size, pred_length, features_j)\n",
    "\n",
    "print(f\"\\nSequence creation results:\")\n",
    "print(f\"  Training set: X{X_train.shape}, y{y_train.shape}\")\n",
    "print(f\"  Validation set: X{X_val.shape}, y{y_val.shape}\")\n",
    "print(f\"  Test set: X{X_test.shape}, y{y_test.shape}\")\n",
    "\n",
    "# 4. Convert to PyTorch tensors\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "y_val_tensor = torch.FloatTensor(y_val).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "print(f\"\\nTensor shapes:\")\n",
    "print(f\"  X_train_tensor: {X_train_tensor.shape}\")\n",
    "print(f\"  y_train_tensor: {y_train_tensor.shape}\")\n",
    "print(f\"  X_val_tensor: {X_val_tensor.shape}\")\n",
    "print(f\"  y_val_tensor: {y_val_tensor.shape}\")\n",
    "print(f\"  X_test_tensor: {X_test_tensor.shape}\")\n",
    "print(f\"  y_test_tensor: {y_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr: 0.03\n",
      "momentum: 0.1\n",
      "weight_decay: 0.001\n",
      "0.03_0.001_RMSE:0.428687\n",
      "0.03_0.001_MAE:0.346937\n",
      "0.03_0.001_MAPE:0.577869\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3534937\n",
      "Best evaluation: 1.3534937\n",
      "\n",
      "lr: 0.03\n",
      "momentum: 0.1\n",
      "weight_decay: 0.0001\n",
      "0.03_0.0001_RMSE:0.427363\n",
      "0.03_0.0001_MAE:0.345656\n",
      "0.03_0.0001_MAPE:0.575970\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3489892\n",
      "Best evaluation: 1.3489892\n",
      "\n",
      "lr: 0.03\n",
      "momentum: 0.1\n",
      "weight_decay: 1e-05\n",
      "0.03_1e-05_RMSE:0.427240\n",
      "0.03_1e-05_MAE:0.345538\n",
      "0.03_1e-05_MAPE:0.575726\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3485044\n",
      "Best evaluation: 1.3485044\n",
      "\n",
      "lr: 0.03\n",
      "momentum: 0.5\n",
      "weight_decay: 0.001\n",
      "0.03_0.001_RMSE:0.428745\n",
      "0.03_0.001_MAE:0.347018\n",
      "0.03_0.001_MAPE:0.580560\n",
      "RMSE_test+MAE_test+MAPE_test: 1.356322\n",
      "\n",
      "lr: 0.03\n",
      "momentum: 0.5\n",
      "weight_decay: 0.0001\n",
      "0.03_0.0001_RMSE:0.427325\n",
      "0.03_0.0001_MAE:0.345659\n",
      "0.03_0.0001_MAPE:0.575907\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3488907\n",
      "\n",
      "lr: 0.03\n",
      "momentum: 0.5\n",
      "weight_decay: 1e-05\n",
      "0.03_1e-05_RMSE:0.427191\n",
      "0.03_1e-05_MAE:0.345530\n",
      "0.03_1e-05_MAPE:0.575500\n",
      "RMSE_test+MAE_test+MAPE_test: 1.348221\n",
      "Best evaluation: 1.348221\n",
      "\n",
      "lr: 0.03\n",
      "momentum: 0.9\n",
      "weight_decay: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_42396\\2194696802.py:64: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(np.abs((pred - true) / true))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03_0.001_RMSE:0.421080\n",
      "0.03_0.001_MAE:0.340253\n",
      "0.03_0.001_MAPE:0.562912\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3242452\n",
      "Best evaluation: 1.3242452\n",
      "\n",
      "lr: 0.03\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0001\n",
      "0.03_0.0001_RMSE:0.419905\n",
      "0.03_0.0001_MAE:0.339131\n",
      "0.03_0.0001_MAPE:0.559616\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3186522\n",
      "Best evaluation: 1.3186522\n",
      "\n",
      "lr: 0.03\n",
      "momentum: 0.9\n",
      "weight_decay: 1e-05\n",
      "0.03_1e-05_RMSE:0.419787\n",
      "0.03_1e-05_MAE:0.339019\n",
      "0.03_1e-05_MAPE:0.559366\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3181723\n",
      "Best evaluation: 1.3181723\n",
      "\n",
      "lr: 0.01\n",
      "momentum: 0.1\n",
      "weight_decay: 0.001\n",
      "0.01_0.001_RMSE:0.429399\n",
      "0.01_0.001_MAE:0.347558\n",
      "0.01_0.001_MAPE:0.581684\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3586414\n",
      "\n",
      "lr: 0.01\n",
      "momentum: 0.1\n",
      "weight_decay: 0.0001\n",
      "0.01_0.0001_RMSE:0.428515\n",
      "0.01_0.0001_MAE:0.346681\n",
      "0.01_0.0001_MAPE:0.580847\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3560426\n",
      "\n",
      "lr: 0.01\n",
      "momentum: 0.1\n",
      "weight_decay: 1e-05\n",
      "0.01_1e-05_RMSE:0.428381\n",
      "0.01_1e-05_MAE:0.346552\n",
      "0.01_1e-05_MAPE:0.580245\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3551781\n",
      "\n",
      "lr: 0.01\n",
      "momentum: 0.5\n",
      "weight_decay: 0.001\n",
      "0.01_0.001_RMSE:0.429349\n",
      "0.01_0.001_MAE:0.347528\n",
      "0.01_0.001_MAPE:0.582645\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3595223\n",
      "\n",
      "lr: 0.01\n",
      "momentum: 0.5\n",
      "weight_decay: 0.0001\n",
      "0.01_0.0001_RMSE:0.427962\n",
      "0.01_0.0001_MAE:0.346197\n",
      "0.01_0.0001_MAPE:0.578948\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3531072\n",
      "\n",
      "lr: 0.01\n",
      "momentum: 0.5\n",
      "weight_decay: 1e-05\n",
      "0.01_1e-05_RMSE:0.427824\n",
      "0.01_1e-05_MAE:0.346064\n",
      "0.01_1e-05_MAPE:0.702058\n",
      "RMSE_test+MAE_test+MAPE_test: 1.4759457\n",
      "\n",
      "lr: 0.01\n",
      "momentum: 0.9\n",
      "weight_decay: 0.001\n",
      "0.01_0.001_RMSE:0.428677\n",
      "0.01_0.001_MAE:0.346973\n",
      "0.01_0.001_MAPE:0.583627\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3592768\n",
      "\n",
      "lr: 0.01\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0001\n",
      "0.01_0.0001_RMSE:0.427234\n",
      "0.01_0.0001_MAE:0.345594\n",
      "0.01_0.0001_MAPE:0.579121\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3519495\n",
      "\n",
      "lr: 0.01\n",
      "momentum: 0.9\n",
      "weight_decay: 1e-05\n",
      "0.01_1e-05_RMSE:0.427098\n",
      "0.01_1e-05_MAE:0.345464\n",
      "0.01_1e-05_MAPE:0.578795\n",
      "RMSE_test+MAE_test+MAPE_test: 1.351357\n",
      "\n",
      "lr: 0.003\n",
      "momentum: 0.1\n",
      "weight_decay: 0.001\n",
      "0.003_0.001_RMSE:0.440055\n",
      "0.003_0.001_MAE:0.356981\n",
      "0.003_0.001_MAPE:0.627010\n",
      "RMSE_test+MAE_test+MAPE_test: 1.4240456\n",
      "\n",
      "lr: 0.003\n",
      "momentum: 0.1\n",
      "weight_decay: 0.0001\n",
      "0.003_0.0001_RMSE:0.438182\n",
      "0.003_0.0001_MAE:0.355194\n",
      "0.003_0.0001_MAPE:0.622037\n",
      "RMSE_test+MAE_test+MAPE_test: 1.415413\n",
      "\n",
      "lr: 0.003\n",
      "momentum: 0.1\n",
      "weight_decay: 1e-05\n",
      "0.003_1e-05_RMSE:0.437998\n",
      "0.003_1e-05_MAE:0.355019\n",
      "0.003_1e-05_MAPE:0.620388\n",
      "RMSE_test+MAE_test+MAPE_test: 1.4134057\n",
      "\n",
      "lr: 0.003\n",
      "momentum: 0.5\n",
      "weight_decay: 0.001\n",
      "0.003_0.001_RMSE:0.429398\n",
      "0.003_0.001_MAE:0.347558\n",
      "0.003_0.001_MAPE:0.582949\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3599046\n",
      "\n",
      "lr: 0.003\n",
      "momentum: 0.5\n",
      "weight_decay: 0.0001\n",
      "0.003_0.0001_RMSE:0.428032\n",
      "0.003_0.0001_MAE:0.346243\n",
      "0.003_0.0001_MAPE:0.590261\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3645358\n",
      "\n",
      "lr: 0.003\n",
      "momentum: 0.5\n",
      "weight_decay: 1e-05\n",
      "0.003_1e-05_RMSE:0.427902\n",
      "0.003_1e-05_MAE:0.346117\n",
      "0.003_1e-05_MAPE:0.578301\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3523196\n",
      "\n",
      "lr: 0.003\n",
      "momentum: 0.9\n",
      "weight_decay: 0.001\n",
      "0.003_0.001_RMSE:0.428957\n",
      "0.003_0.001_MAE:0.347176\n",
      "0.003_0.001_MAPE:0.580156\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3562891\n",
      "\n",
      "lr: 0.003\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0001\n",
      "0.003_0.0001_RMSE:0.428546\n",
      "0.003_0.0001_MAE:0.346705\n",
      "0.003_0.0001_MAPE:0.582177\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3574282\n",
      "\n",
      "lr: 0.003\n",
      "momentum: 0.9\n",
      "weight_decay: 1e-05\n",
      "0.003_1e-05_RMSE:0.428408\n",
      "0.003_1e-05_MAE:0.346573\n",
      "0.003_1e-05_MAPE:0.581903\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3568838\n",
      "\n",
      "lr: 0.001\n",
      "momentum: 0.1\n",
      "weight_decay: 0.001\n",
      "0.001_0.001_RMSE:0.923383\n",
      "0.001_0.001_MAE:0.831721\n",
      "0.001_0.001_MAPE:59.809616\n",
      "RMSE_test+MAE_test+MAPE_test: 61.56472\n",
      "\n",
      "lr: 0.001\n",
      "momentum: 0.1\n",
      "weight_decay: 0.0001\n",
      "0.001_0.0001_RMSE:0.923558\n",
      "0.001_0.0001_MAE:0.831758\n",
      "0.001_0.0001_MAPE:51.844158\n",
      "RMSE_test+MAE_test+MAPE_test: 53.599472\n",
      "\n",
      "lr: 0.001\n",
      "momentum: 0.1\n",
      "weight_decay: 1e-05\n",
      "0.001_1e-05_RMSE:0.930685\n",
      "0.001_1e-05_MAE:0.839409\n",
      "0.001_1e-05_MAPE:51.862434\n",
      "RMSE_test+MAE_test+MAPE_test: 53.63253\n",
      "\n",
      "lr: 0.001\n",
      "momentum: 0.5\n",
      "weight_decay: 0.001\n",
      "0.001_0.001_RMSE:0.616515\n",
      "0.001_0.001_MAE:0.521921\n",
      "0.001_0.001_MAPE:2.496137\n",
      "RMSE_test+MAE_test+MAPE_test: 3.6345735\n",
      "\n",
      "lr: 0.001\n",
      "momentum: 0.5\n",
      "weight_decay: 0.0001\n",
      "0.001_0.0001_RMSE:0.613106\n",
      "0.001_0.0001_MAE:0.518387\n",
      "0.001_0.0001_MAPE:2.227931\n",
      "RMSE_test+MAE_test+MAPE_test: 3.3594244\n",
      "\n",
      "lr: 0.001\n",
      "momentum: 0.5\n",
      "weight_decay: 1e-05\n",
      "0.001_1e-05_RMSE:0.612768\n",
      "0.001_1e-05_MAE:0.518035\n",
      "0.001_1e-05_MAPE:2.332802\n",
      "RMSE_test+MAE_test+MAPE_test: 3.4636047\n",
      "\n",
      "lr: 0.001\n",
      "momentum: 0.9\n",
      "weight_decay: 0.001\n",
      "0.001_0.001_RMSE:0.429298\n",
      "0.001_0.001_MAE:0.347475\n",
      "0.001_0.001_MAPE:0.582787\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3595608\n",
      "\n",
      "lr: 0.001\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0001\n",
      "0.001_0.0001_RMSE:0.428198\n",
      "0.001_0.0001_MAE:0.346402\n",
      "0.001_0.0001_MAPE:0.580129\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3547279\n",
      "\n",
      "lr: 0.001\n",
      "momentum: 0.9\n",
      "weight_decay: 1e-05\n",
      "0.001_1e-05_RMSE:0.428062\n",
      "0.001_1e-05_MAE:0.346271\n",
      "0.001_1e-05_MAPE:0.579188\n",
      "RMSE_test+MAE_test+MAPE_test: 1.3535218\n",
      "\n",
      "lr: 0.0003\n",
      "momentum: 0.1\n",
      "weight_decay: 0.001\n",
      "0.0003_0.001_RMSE:1.047445\n",
      "0.0003_0.001_MAE:0.963449\n",
      "0.0003_0.001_MAPE:108.094414\n",
      "RMSE_test+MAE_test+MAPE_test: 110.10531\n",
      "\n",
      "lr: 0.0003\n",
      "momentum: 0.1\n",
      "weight_decay: 0.0001\n",
      "0.0003_0.0001_RMSE:1.043774\n",
      "0.0003_0.0001_MAE:0.959970\n",
      "0.0003_0.0001_MAPE:101.055847\n",
      "RMSE_test+MAE_test+MAPE_test: 103.05959\n",
      "\n",
      "lr: 0.0003\n",
      "momentum: 0.1\n",
      "weight_decay: 1e-05\n",
      "0.0003_1e-05_RMSE:1.037485\n",
      "0.0003_1e-05_MAE:0.953757\n",
      "0.0003_1e-05_MAPE:105.668747\n",
      "RMSE_test+MAE_test+MAPE_test: 107.65999\n",
      "\n",
      "lr: 0.0003\n",
      "momentum: 0.5\n",
      "weight_decay: 0.001\n",
      "0.0003_0.001_RMSE:1.034290\n",
      "0.0003_0.001_MAE:0.950557\n",
      "0.0003_0.001_MAPE:247.915924\n",
      "RMSE_test+MAE_test+MAPE_test: 249.90077\n",
      "\n",
      "lr: 0.0003\n",
      "momentum: 0.5\n",
      "weight_decay: 0.0001\n",
      "0.0003_0.0001_RMSE:1.022670\n",
      "0.0003_0.0001_MAE:0.938449\n",
      "0.0003_0.0001_MAPE:146.583572\n",
      "RMSE_test+MAE_test+MAPE_test: 148.5447\n",
      "\n",
      "lr: 0.0003\n",
      "momentum: 0.5\n",
      "weight_decay: 1e-05\n",
      "0.0003_1e-05_RMSE:1.046306\n",
      "0.0003_1e-05_MAE:0.962383\n",
      "0.0003_1e-05_MAPE:96.431290\n",
      "RMSE_test+MAE_test+MAPE_test: 98.43998\n",
      "\n",
      "lr: 0.0003\n",
      "momentum: 0.9\n",
      "weight_decay: 0.001\n",
      "0.0003_0.001_RMSE:0.455553\n",
      "0.0003_0.001_MAE:0.370836\n",
      "0.0003_0.001_MAPE:0.692708\n",
      "RMSE_test+MAE_test+MAPE_test: 1.5190972\n",
      "\n",
      "lr: 0.0003\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0001\n",
      "0.0003_0.0001_RMSE:0.453208\n",
      "0.0003_0.0001_MAE:0.368576\n",
      "0.0003_0.0001_MAPE:0.690065\n",
      "RMSE_test+MAE_test+MAPE_test: 1.5118489\n",
      "\n",
      "lr: 0.0003\n",
      "momentum: 0.9\n",
      "weight_decay: 1e-05\n",
      "0.0003_1e-05_RMSE:0.452979\n",
      "0.0003_1e-05_MAE:0.368355\n",
      "0.0003_1e-05_MAPE:0.796191\n",
      "RMSE_test+MAE_test+MAPE_test: 1.6175253\n",
      "best_lr: 0.03\n",
      "best_weight_decay: 1e-05\n",
      "best_momentum: 0.9\n",
      "best_evaluation: 1.3181723\n"
     ]
    }
   ],
   "source": [
    "# momentums = [0.1,0.5,0.9]\n",
    "weight_decays = [1e-3,1e-4,1e-5]\n",
    "lrs = [3e-2,1e-2,3e-3,1e-3,3e-4]             \n",
    "\n",
    "# root = r'C:\\Users\\Administrator\\torch_zxj\\博士第四篇代码'\n",
    "# batch_size = 256\n",
    "num_epochs = 200\n",
    "set_seed()\n",
    "# train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1=512, hidden_size2=256,output_size=pred_length):  \n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        # self.linear1 = FLinear(input_size, hidden_size1, alpha,c) \n",
    "        self.linear1 = nn.Linear(input_size, hidden_size1)    \n",
    "        self.leakrelu1 = nn.LeakyReLU()                          \n",
    "        # self.linear2 = FLinear(hidden_size1, hidden_size2, alpha,c) \n",
    "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)    \n",
    "        self.leakrelu2 = nn.LeakyReLU()\n",
    "        # self.linear3 = FLinear(hidden_size2, output_size, alpha,c)  \n",
    "        self.linear3 = nn.Linear(hidden_size2, output_size)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)    # (batch_size, seq_len*num_features)\n",
    "        x = self.leakrelu1(self.linear1(x))\n",
    "        x = self.leakrelu2(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "best_lr = 0\n",
    "best_momentum = 0\n",
    "best_weight_decay = 0\n",
    "best_evaluation = 10000\n",
    "for lr in lrs:\n",
    "    for weight_decay in weight_decays:   \n",
    "        print('')\n",
    "        print('lr:',lr)\n",
    "        print('weight_decay:',weight_decay)\n",
    "        set_seed()\n",
    "        model = MLP(input_size=slide_windows_size*num_feature).to(device)\n",
    "        best_loss = 10000\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer_base = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)   #adam\n",
    "        optimizer = Lookahead(optimizer_base)\n",
    "        for ii in range(num_epochs):\n",
    "            model.train()\n",
    "            loss_sum = 0\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss_sum += loss\n",
    "                loss.backward()   #The default value of retain_graph is False.\n",
    "                optimizer.step()\n",
    "                \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                Val_outputs = model(X_val_tensor)\n",
    "                RMSE_val = RMSE(y_val_tensor.cpu().detach().numpy(),Val_outputs.cpu().detach().numpy())\n",
    "                MAE_val = MAE(y_val_tensor.cpu().detach().numpy(),Val_outputs.cpu().detach().numpy())\n",
    "                MAPE_val = MAPE(y_val_tensor.cpu().detach().numpy(),Val_outputs.cpu().detach().numpy())\n",
    "                best_val = RMSE_val + MAE_val+MAPE_val\n",
    "\n",
    "                if best_loss > best_val:\n",
    "                    best_loss = best_val\n",
    "                    torch.save(model.state_dict(), root+'/model/table4/'+stock+'_model_fractional'+'_'+str(weight_decay)+'_'+str(lr)+'_.pth')    #adam\n",
    "\n",
    "        model.load_state_dict(torch.load(root+'/model/table4/'+stock+'_model_fractional'+'_'+str(weight_decay)+'_'+str(lr)+'_.pth'))   #adam\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_tensor)\n",
    "        RMSE_test = RMSE(y_test_tensor.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "        MAE_test = MAE(y_test_tensor.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "        MAPE_test = MAPE(y_test_tensor.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "        print(str(lr)+'_'+str(weight_decay)+'_'+f'RMSE:{RMSE_test:.6f}')\n",
    "        print(str(lr)+'_'+str(weight_decay)+'_'+f'MAE:{MAE_test:.6f}')\n",
    "        print(str(lr)+'_'+str(weight_decay)+'_'+f'MAPE:{MAPE_test:.6f}')\n",
    "        print('RMSE_test+MAE_test+MAPE_test:',RMSE_test+MAE_test+MAPE_test)\n",
    "        if best_evaluation > RMSE_test + MAE_test + MAPE_test:\n",
    "            best_evaluation = RMSE_test + MAE_test + MAPE_test\n",
    "            print('Best evaluation:',best_evaluation)\n",
    "            best_lr = lr\n",
    "            best_weight_decay = weight_decay\n",
    "print('best_lr:',best_lr)\n",
    "print('best_weight_decay:',best_weight_decay)\n",
    "print('best_evaluation:',best_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alpha: 1.0\n",
      "c: 0.1\n",
      "RMSE:0.419787\n",
      "MAE:0.339019\n",
      "MAPE:0.559364\n",
      "RMSE+MAE+MAPE:1.318171\n",
      "Best evaluation: 1.3181708\n",
      "\n",
      "alpha: 1.0\n",
      "c: 0.2\n",
      "RMSE:0.419787\n",
      "MAE:0.339019\n",
      "MAPE:0.559364\n",
      "RMSE+MAE+MAPE:1.318171\n",
      "\n",
      "alpha: 1.0\n",
      "c: 0.5\n",
      "RMSE:0.419787\n",
      "MAE:0.339019\n",
      "MAPE:0.559364\n",
      "RMSE+MAE+MAPE:1.318171\n",
      "\n",
      "alpha: 1.0\n",
      "c: 1.0\n",
      "RMSE:0.419787\n",
      "MAE:0.339019\n",
      "MAPE:0.559364\n",
      "RMSE+MAE+MAPE:1.318171\n",
      "\n",
      "alpha: 1.0\n",
      "c: 2.0\n",
      "RMSE:0.419787\n",
      "MAE:0.339019\n",
      "MAPE:0.559364\n",
      "RMSE+MAE+MAPE:1.318171\n",
      "\n",
      "alpha: 1.0\n",
      "c: 5.0\n",
      "RMSE:0.419787\n",
      "MAE:0.339019\n",
      "MAPE:0.559364\n",
      "RMSE+MAE+MAPE:1.318171\n",
      "\n",
      "alpha: 1.0\n",
      "c: 10.0\n",
      "RMSE:0.419787\n",
      "MAE:0.339019\n",
      "MAPE:0.559364\n",
      "RMSE+MAE+MAPE:1.318171\n",
      "\n",
      "alpha: 0.9\n",
      "c: 0.1\n",
      "RMSE:0.424161\n",
      "MAE:0.342879\n",
      "MAPE:0.567814\n",
      "RMSE+MAE+MAPE:1.334854\n",
      "\n",
      "alpha: 0.9\n",
      "c: 0.2\n",
      "RMSE:0.424168\n",
      "MAE:0.342884\n",
      "MAPE:0.567865\n",
      "RMSE+MAE+MAPE:1.334917\n",
      "\n",
      "alpha: 0.9\n",
      "c: 0.5\n",
      "RMSE:0.424162\n",
      "MAE:0.342878\n",
      "MAPE:0.567817\n",
      "RMSE+MAE+MAPE:1.334857\n",
      "\n",
      "alpha: 0.9\n",
      "c: 1.0\n",
      "RMSE:0.424147\n",
      "MAE:0.342861\n",
      "MAPE:0.567845\n",
      "RMSE+MAE+MAPE:1.334852\n",
      "\n",
      "alpha: 0.9\n",
      "c: 2.0\n",
      "RMSE:0.424164\n",
      "MAE:0.342870\n",
      "MAPE:0.568287\n",
      "RMSE+MAE+MAPE:1.335320\n",
      "\n",
      "alpha: 0.9\n",
      "c: 5.0\n",
      "RMSE:0.424181\n",
      "MAE:0.342887\n",
      "MAPE:0.568034\n",
      "RMSE+MAE+MAPE:1.335102\n",
      "\n",
      "alpha: 0.9\n",
      "c: 10.0\n",
      "RMSE:0.425160\n",
      "MAE:0.343760\n",
      "MAPE:0.573267\n",
      "RMSE+MAE+MAPE:1.342187\n",
      "\n",
      "alpha: 0.8\n",
      "c: 0.1\n",
      "RMSE:0.424759\n",
      "MAE:0.343268\n",
      "MAPE:0.557454\n",
      "RMSE+MAE+MAPE:1.325481\n",
      "\n",
      "alpha: 0.8\n",
      "c: 0.2\n",
      "RMSE:0.424788\n",
      "MAE:0.343295\n",
      "MAPE:0.557562\n",
      "RMSE+MAE+MAPE:1.325645\n",
      "\n",
      "alpha: 0.8\n",
      "c: 0.5\n",
      "RMSE:0.424744\n",
      "MAE:0.343255\n",
      "MAPE:0.557410\n",
      "RMSE+MAE+MAPE:1.325408\n",
      "\n",
      "alpha: 0.8\n",
      "c: 1.0\n",
      "RMSE:0.424712\n",
      "MAE:0.343231\n",
      "MAPE:0.557348\n",
      "RMSE+MAE+MAPE:1.325292\n",
      "\n",
      "alpha: 0.8\n",
      "c: 2.0\n",
      "RMSE:0.424771\n",
      "MAE:0.343277\n",
      "MAPE:0.557382\n",
      "RMSE+MAE+MAPE:1.325430\n",
      "\n",
      "alpha: 0.8\n",
      "c: 5.0\n",
      "RMSE:0.425683\n",
      "MAE:0.344071\n",
      "MAPE:0.560874\n",
      "RMSE+MAE+MAPE:1.330628\n",
      "\n",
      "alpha: 0.8\n",
      "c: 10.0\n",
      "RMSE:0.425356\n",
      "MAE:0.343779\n",
      "MAPE:0.559775\n",
      "RMSE+MAE+MAPE:1.328910\n",
      "\n",
      "alpha: 0.7\n",
      "c: 0.1\n",
      "RMSE:0.424960\n",
      "MAE:0.343416\n",
      "MAPE:0.554342\n",
      "RMSE+MAE+MAPE:1.322718\n",
      "\n",
      "alpha: 0.7\n",
      "c: 0.2\n",
      "RMSE:0.424964\n",
      "MAE:0.343419\n",
      "MAPE:0.554347\n",
      "RMSE+MAE+MAPE:1.322730\n",
      "\n",
      "alpha: 0.7\n",
      "c: 0.5\n",
      "RMSE:0.424996\n",
      "MAE:0.343448\n",
      "MAPE:0.554485\n",
      "RMSE+MAE+MAPE:1.322929\n",
      "\n",
      "alpha: 0.7\n",
      "c: 1.0\n",
      "RMSE:0.425659\n",
      "MAE:0.344038\n",
      "MAPE:0.557193\n",
      "RMSE+MAE+MAPE:1.326890\n",
      "\n",
      "alpha: 0.7\n",
      "c: 2.0\n",
      "RMSE:0.425462\n",
      "MAE:0.343847\n",
      "MAPE:0.556168\n",
      "RMSE+MAE+MAPE:1.325478\n",
      "\n",
      "alpha: 0.7\n",
      "c: 5.0\n",
      "RMSE:0.425093\n",
      "MAE:0.343485\n",
      "MAPE:0.554703\n",
      "RMSE+MAE+MAPE:1.323281\n",
      "\n",
      "alpha: 0.7\n",
      "c: 10.0\n",
      "RMSE:0.425554\n",
      "MAE:0.343872\n",
      "MAPE:0.558209\n",
      "RMSE+MAE+MAPE:1.327636\n",
      "\n",
      "alpha: 0.6\n",
      "c: 0.1\n",
      "RMSE:0.425285\n",
      "MAE:0.343554\n",
      "MAPE:0.549384\n",
      "RMSE+MAE+MAPE:1.318223\n",
      "\n",
      "alpha: 0.6\n",
      "c: 0.2\n",
      "RMSE:0.425290\n",
      "MAE:0.343557\n",
      "MAPE:0.549414\n",
      "RMSE+MAE+MAPE:1.318262\n",
      "\n",
      "alpha: 0.6\n",
      "c: 0.5\n",
      "RMSE:0.425565\n",
      "MAE:0.343798\n",
      "MAPE:0.550568\n",
      "RMSE+MAE+MAPE:1.319931\n",
      "\n",
      "alpha: 0.6\n",
      "c: 1.0\n",
      "RMSE:0.425458\n",
      "MAE:0.343691\n",
      "MAPE:0.550123\n",
      "RMSE+MAE+MAPE:1.319272\n",
      "\n",
      "alpha: 0.6\n",
      "c: 2.0\n",
      "RMSE:0.425162\n",
      "MAE:0.343411\n",
      "MAPE:0.549014\n",
      "RMSE+MAE+MAPE:1.317587\n",
      "Best evaluation: 1.3175865\n",
      "\n",
      "alpha: 0.6\n",
      "c: 5.0\n",
      "RMSE:0.425079\n",
      "MAE:0.343302\n",
      "MAPE:0.550135\n",
      "RMSE+MAE+MAPE:1.318516\n",
      "\n",
      "alpha: 0.6\n",
      "c: 10.0\n",
      "RMSE:0.421617\n",
      "MAE:0.340283\n",
      "MAPE:0.538093\n",
      "RMSE+MAE+MAPE:1.299993\n",
      "Best evaluation: 1.299993\n",
      "\n",
      "alpha: 0.5\n",
      "c: 0.1\n",
      "RMSE:0.424294\n",
      "MAE:0.342437\n",
      "MAPE:0.538301\n",
      "RMSE+MAE+MAPE:1.305032\n",
      "\n",
      "alpha: 0.5\n",
      "c: 0.2\n",
      "RMSE:0.424248\n",
      "MAE:0.342394\n",
      "MAPE:0.538128\n",
      "RMSE+MAE+MAPE:1.304770\n",
      "\n",
      "alpha: 0.5\n",
      "c: 0.5\n",
      "RMSE:0.424133\n",
      "MAE:0.342281\n",
      "MAPE:0.537655\n",
      "RMSE+MAE+MAPE:1.304069\n",
      "\n",
      "alpha: 0.5\n",
      "c: 1.0\n",
      "RMSE:0.424463\n",
      "MAE:0.342639\n",
      "MAPE:0.540296\n",
      "RMSE+MAE+MAPE:1.307398\n",
      "\n",
      "alpha: 0.5\n",
      "c: 2.0\n",
      "RMSE:0.423813\n",
      "MAE:0.342041\n",
      "MAPE:0.538230\n",
      "RMSE+MAE+MAPE:1.304085\n",
      "\n",
      "alpha: 0.5\n",
      "c: 5.0\n",
      "RMSE:0.421643\n",
      "MAE:0.340119\n",
      "MAPE:0.531100\n",
      "RMSE+MAE+MAPE:1.292863\n",
      "Best evaluation: 1.2928627\n",
      "\n",
      "alpha: 0.5\n",
      "c: 10.0\n",
      "RMSE:0.418629\n",
      "MAE:0.337434\n",
      "MAPE:0.522717\n",
      "RMSE+MAE+MAPE:1.278780\n",
      "Best evaluation: 1.2787805\n",
      "\n",
      "alpha: 0.4\n",
      "c: 0.1\n",
      "RMSE:0.423641\n",
      "MAE:0.341601\n",
      "MAPE:0.528814\n",
      "RMSE+MAE+MAPE:1.294056\n",
      "\n",
      "alpha: 0.4\n",
      "c: 0.2\n",
      "RMSE:0.423564\n",
      "MAE:0.341528\n",
      "MAPE:0.528532\n",
      "RMSE+MAE+MAPE:1.293624\n",
      "\n",
      "alpha: 0.4\n",
      "c: 0.5\n",
      "RMSE:0.423369\n",
      "MAE:0.341338\n",
      "MAPE:0.527803\n",
      "RMSE+MAE+MAPE:1.292510\n",
      "\n",
      "alpha: 0.4\n",
      "c: 1.0\n",
      "RMSE:0.422983\n",
      "MAE:0.340974\n",
      "MAPE:0.526398\n",
      "RMSE+MAE+MAPE:1.290355\n",
      "\n",
      "alpha: 0.4\n",
      "c: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_42396\\2194696802.py:64: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(np.abs((pred - true) / true))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:0.422435\n",
      "MAE:0.340502\n",
      "MAPE:0.525353\n",
      "RMSE+MAE+MAPE:1.288290\n",
      "\n",
      "alpha: 0.4\n",
      "c: 5.0\n",
      "RMSE:0.419156\n",
      "MAE:0.337647\n",
      "MAPE:0.516229\n",
      "RMSE+MAE+MAPE:1.273032\n",
      "Best evaluation: 1.2730322\n",
      "\n",
      "alpha: 0.4\n",
      "c: 10.0\n",
      "RMSE:0.416718\n",
      "MAE:0.335355\n",
      "MAPE:0.509216\n",
      "RMSE+MAE+MAPE:1.261288\n",
      "Best evaluation: 1.2612884\n",
      "\n",
      "alpha: 0.3\n",
      "c: 0.1\n",
      "RMSE:0.422334\n",
      "MAE:0.340023\n",
      "MAPE:0.515725\n",
      "RMSE+MAE+MAPE:1.278082\n",
      "\n",
      "alpha: 0.3\n",
      "c: 0.2\n",
      "RMSE:0.422215\n",
      "MAE:0.339910\n",
      "MAPE:0.515332\n",
      "RMSE+MAE+MAPE:1.277457\n",
      "\n",
      "alpha: 0.3\n",
      "c: 0.5\n",
      "RMSE:0.421835\n",
      "MAE:0.339554\n",
      "MAPE:0.514042\n",
      "RMSE+MAE+MAPE:1.275432\n",
      "\n",
      "alpha: 0.3\n",
      "c: 1.0\n",
      "RMSE:0.421427\n",
      "MAE:0.339213\n",
      "MAPE:0.513466\n",
      "RMSE+MAE+MAPE:1.274106\n",
      "\n",
      "alpha: 0.3\n",
      "c: 2.0\n",
      "RMSE:0.419874\n",
      "MAE:0.337823\n",
      "MAPE:0.508903\n",
      "RMSE+MAE+MAPE:1.266600\n",
      "\n",
      "alpha: 0.3\n",
      "c: 5.0\n",
      "RMSE:0.417231\n",
      "MAE:0.335524\n",
      "MAPE:0.502769\n",
      "RMSE+MAE+MAPE:1.255524\n",
      "Best evaluation: 1.2555237\n",
      "\n",
      "alpha: 0.3\n",
      "c: 10.0\n",
      "RMSE:0.416853\n",
      "MAE:0.334797\n",
      "MAPE:0.498591\n",
      "RMSE+MAE+MAPE:1.250242\n",
      "Best evaluation: 1.2502415\n",
      "\n",
      "alpha: 0.2\n",
      "c: 0.1\n",
      "RMSE:0.421318\n",
      "MAE:0.338499\n",
      "MAPE:0.502591\n",
      "RMSE+MAE+MAPE:1.262408\n",
      "\n",
      "alpha: 0.2\n",
      "c: 0.2\n",
      "RMSE:0.421436\n",
      "MAE:0.338640\n",
      "MAPE:0.503193\n",
      "RMSE+MAE+MAPE:1.263269\n",
      "\n",
      "alpha: 0.2\n",
      "c: 0.5\n",
      "RMSE:0.420767\n",
      "MAE:0.338033\n",
      "MAPE:0.501171\n",
      "RMSE+MAE+MAPE:1.259970\n",
      "\n",
      "alpha: 0.2\n",
      "c: 1.0\n",
      "RMSE:0.420086\n",
      "MAE:0.337455\n",
      "MAPE:0.499729\n",
      "RMSE+MAE+MAPE:1.257270\n",
      "\n",
      "alpha: 0.2\n",
      "c: 2.0\n",
      "RMSE:0.417439\n",
      "MAE:0.335174\n",
      "MAPE:0.493084\n",
      "RMSE+MAE+MAPE:1.245697\n",
      "Best evaluation: 1.245697\n",
      "\n",
      "alpha: 0.2\n",
      "c: 5.0\n",
      "RMSE:0.414872\n",
      "MAE:0.332876\n",
      "MAPE:0.486530\n",
      "RMSE+MAE+MAPE:1.234278\n",
      "Best evaluation: 1.2342781\n",
      "\n",
      "alpha: 0.2\n",
      "c: 10.0\n",
      "RMSE:0.417232\n",
      "MAE:0.334526\n",
      "MAPE:0.487982\n",
      "RMSE+MAE+MAPE:1.239740\n",
      "best_alpha: 0.2\n",
      "best_c: 5.0\n",
      "best_evaluation: 1.2342781\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 1e-5\n",
    "lr = 0.03\n",
    "\n",
    "alphas = [0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2]    # DJI:0.999,0.99,0.98,0.95,0.9,0.85,0.8,0.75  ETTh1:0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2\n",
    "cs = [0.1,0.2,0.5,1.0,2.0,5.0,10.0]\n",
    "\n",
    "# root = r'C:\\Users\\Administrator\\torch_zxj\\博士第四篇代码'\n",
    "# batch_size = 256\n",
    "num_epochs = 200\n",
    "set_seed()\n",
    "# train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1=512, hidden_size2=256,output_size=pred_length):  \n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = FLinear(input_size, hidden_size1, alpha,c) \n",
    "        # self.linear1 = nn.Linear(input_size, hidden_size1)    \n",
    "        self.leakrelu1 = nn.LeakyReLU()                          \n",
    "        self.linear2 = FLinear(hidden_size1, hidden_size2, alpha,c) \n",
    "        # self.linear2 = nn.Linear(hidden_size1, hidden_size2)    \n",
    "        self.leakrelu2 = nn.LeakyReLU()\n",
    "        self.linear3 = FLinear(hidden_size2, output_size, alpha,c)  \n",
    "        # self.linear3 = nn.Linear(hidden_size2, output_size)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)    # (batch_size, seq_len*num_features)\n",
    "        x = self.leakrelu1(self.linear1(x))\n",
    "        x = self.leakrelu2(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "best_c = 0\n",
    "best_alpha = 0\n",
    "best_evaluation = 10000\n",
    "for alpha in alphas:\n",
    "    for c in cs:\n",
    "        print('')\n",
    "        print('alpha:',alpha)\n",
    "        print('c:',c)\n",
    "        set_seed()\n",
    "        model = MLP(input_size=slide_windows_size*num_feature).to(device)\n",
    "        best_loss = 10000\n",
    "        criterion = nn.MSELoss()\n",
    "        # optimizer_base = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)   #adam\n",
    "        optimizer_base = torch.optim.SGD(model.parameters(), lr=lr,weight_decay=weight_decay,momentum=momentum)   #sgd\n",
    "        optimizer = Lookahead(optimizer_base)\n",
    "        for ii in range(num_epochs):\n",
    "            model.train()\n",
    "            loss_sum = 0\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss_sum += loss\n",
    "                loss.backward()   #The default value of retain_graph is False.\n",
    "                optimizer.step()\n",
    "                \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                Val_outputs = model(X_val_tensor)\n",
    "                RMSE_val = RMSE(y_val_tensor.cpu().detach().numpy(),Val_outputs.cpu().detach().numpy())\n",
    "                MAE_val = MAE(y_val_tensor.cpu().detach().numpy(),Val_outputs.cpu().detach().numpy())\n",
    "                MAPE_val = MAPE(y_val_tensor.cpu().detach().numpy(),Val_outputs.cpu().detach().numpy())\n",
    "                best_val = RMSE_val + MAE_val+MAPE_val\n",
    "\n",
    "                if best_loss > best_val:\n",
    "                    best_loss = best_val\n",
    "                    torch.save(model.state_dict(), root+'/model/table4/'+stock+'_model_fractional_adam'+'_'+str(weight_decay)+'_'+str(lr)+'_'+str(alpha)+'_'+str(c)+'_.pth')  #Fadam\n",
    "\n",
    "        model.load_state_dict(torch.load(root+'/model/table4/'+stock+'_model_fractional_adam'+'_'+str(weight_decay)+'_'+str(lr)+'_'+str(alpha)+'_'+str(c)+'_.pth'))   #Fadam\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_tensor)\n",
    "        RMSE_test = RMSE(y_test_tensor.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "        MAE_test = MAE(y_test_tensor.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "        MAPE_test = MAPE(y_test_tensor.cpu().numpy(),test_outputs.cpu().detach().numpy())\n",
    "        print(f'RMSE:{RMSE_test:.6f}')\n",
    "        print(f'MAE:{MAE_test:.6f}')\n",
    "        print(f'MAPE:{MAPE_test:.6f}')\n",
    "        print(f'RMSE+MAE+MAPE:{RMSE_test+MAE_test+MAPE_test:.6f}')\n",
    "        if best_evaluation > RMSE_test + MAE_test + MAPE_test:\n",
    "            best_evaluation = RMSE_test + MAE_test + MAPE_test\n",
    "            print('Best evaluation:',best_evaluation)\n",
    "            best_alpha = alpha\n",
    "            best_c = c\n",
    "print('best_alpha:',best_alpha)\n",
    "print('best_c:',best_c)\n",
    "print('best_evaluation:',best_evaluation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_12_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
